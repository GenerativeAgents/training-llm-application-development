import os
from typing import Sequence

import streamlit as st
import weave
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model
from langchain_core.documents import Document
from pydantic import BaseModel
from streamlit_feedback import streamlit_feedback  # type: ignore[import-untyped]

from app.advanced_rag.chains.base import AnswerToken, Context, WeaveCallId
from app.advanced_rag.factory import chain_constructor_by_name, create_rag_chain


class SessionState(BaseModel):
    question: str | None
    context: list[Document] | None
    answer: str | None
    weave_call_id: str | None


def show_context(context: Sequence[Document]) -> None:
    st.write("### æ¤œç´¢çµæœ")
    for doc in context:
        source = doc.metadata["source"]
        content = doc.page_content
        with st.expander(source):
            st.text(content)


def app() -> None:
    load_dotenv(override=True)
    weave.init(os.getenv("WEAVE_PROJECT_NAME"))

    # ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–
    if "state" not in st.session_state:
        st.session_state.state = SessionState(
            question=None,
            context=None,
            answer=None,
            weave_call_id=None,
        )

    with st.sidebar:
        reasoning_effort = st.selectbox(
            label="reasoning_effort",
            options=["minimal", "low", "medium", "high"],
        )
        chain_name = st.selectbox(
            label="RAG Chain Type",
            options=chain_constructor_by_name.keys(),
        )

    st.title("Advanced RAG")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å—ã‘ä»˜ã‘ã‚‹
    question = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if not question:
        return

    # è³ªå•ãŒå¤‰ã‚ã£ãŸå ´åˆ
    if question != st.session_state.state.question:
        st.session_state.state.question = question

        # å›ç­”ã‚’ç”Ÿæˆã—ã¦è¡¨ç¤º
        model = init_chat_model(
            model="gpt-5-nano",
            model_provider="openai",
            reasoning_effort=reasoning_effort,
        )
        chain = create_rag_chain(chain_name=chain_name, model=model)

        answer_start = False
        answer = ""
        for chunk in chain.stream(question):
            if isinstance(chunk, WeaveCallId):
                weave_call_id = chunk.weave_call_id
                st.session_state.state.weave_call_id = weave_call_id

            if isinstance(chunk, Context):
                context = chunk.documents
                show_context(context)
                st.session_state.state.context = context

            if isinstance(chunk, AnswerToken):
                if not answer_start:
                    answer_start = True
                    st.write("### å›ç­”")
                    placeholder = st.empty()

                answer += chunk.token
                placeholder.write(answer)

            st.session_state.state.answer = answer
    else:
        context = st.session_state.state.context
        show_context(context)
        st.write("### å›ç­”")
        st.write(st.session_state.state.answer)

    # å®Ÿè¡Œå¾Œã®å ´åˆã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘ä»˜ã‘ã‚‹
    if st.session_state.state.weave_call_id is not None:
        weave_call_id = st.session_state.state.weave_call_id

        feedback = streamlit_feedback(
            feedback_type="thumbs",
            optional_text_label="[Optional] Please provide an explanation",
            key=str(weave_call_id),
        )

        if feedback:
            scores = {"ğŸ‘": 1, "ğŸ‘": 0}
            score_key = feedback["score"]
            score = scores[score_key]
            comment = feedback.get("text")

            client = weave.init(os.getenv("WEAVE_PROJECT_NAME"))
            call = client.get_call(weave_call_id)

            call.feedback.add_reaction(score_key)
            call.feedback.add("score", {"value": score})
            if comment:
                call.feedback.add_note(comment)


app()
