{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 入門\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:13.418943Z",
     "iopub.status.busy": "2025-02-16T03:27:13.418575Z",
     "iopub.status.idle": "2025-02-16T03:27:13.434733Z",
     "shell.execute_reply": "2025-02-16T03:27:13.434260Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatOpenAI の基本的な使い方\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:13.437318Z",
     "iopub.status.busy": "2025-02-16T03:27:13.436978Z",
     "iopub.status.idle": "2025-02-16T03:27:14.936196Z",
     "shell.execute_reply": "2025-02-16T03:27:14.935709Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"こんにちは！私はジョンと言います\"),\n",
    "    AIMessage(\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
    "    HumanMessage(\"私の名前がわかりますか？\"),\n",
    "]\n",
    "\n",
    "ai_message = model.invoke(messages)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ストリーミング\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:14.938594Z",
     "iopub.status.busy": "2025-02-16T03:27:14.938387Z",
     "iopub.status.idle": "2025-02-16T03:27:15.460787Z",
     "shell.execute_reply": "2025-02-16T03:27:15.460143Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"こんにちは！\"),\n",
    "]\n",
    "\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:15.463293Z",
     "iopub.status.busy": "2025-02-16T03:27:15.463086Z",
     "iopub.status.idle": "2025-02-16T03:27:15.637240Z",
     "shell.execute_reply": "2025-02-16T03:27:15.634103Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_value = prompt.invoke({\"dish\": \"カレー\"})\n",
    "for message in prompt_value.messages:\n",
    "    print(f\"{message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MessagesPlaceholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:15.655402Z",
     "iopub.status.busy": "2025-02-16T03:27:15.655194Z",
     "iopub.status.idle": "2025-02-16T03:27:15.667206Z",
     "shell.execute_reply": "2025-02-16T03:27:15.664119Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_value = prompt.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"こんにちは！私はジョンと言います！\"),\n",
    "            AIMessage(\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
    "        ],\n",
    "        \"input\": \"私の名前が分かりますか？\",\n",
    "    }\n",
    ")\n",
    "for message in prompt_value.messages:\n",
    "    print(f\"{message.type}: {message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PydanticOutputParser を使った Python オブジェクトへの変換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:15.672312Z",
     "iopub.status.busy": "2025-02-16T03:27:15.671899Z",
     "iopub.status.idle": "2025-02-16T03:27:15.684117Z",
     "shell.execute_reply": "2025-02-16T03:27:15.681704Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "_system_prompt = \"\"\"\\\n",
    "ユーザーが入力した料理のレシピを考えてください。\n",
    "\n",
    "出力は以下のJSON形式にしてください。\n",
    "{{\n",
    "  \"ingredients\": [\"材料1\", \"材料2\"]\n",
    "  \"steps\": [\"ステップ1\", \"ステップ2\"]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", _system_prompt),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:15.713763Z",
     "iopub.status.busy": "2025-02-16T03:27:15.713618Z",
     "iopub.status.idle": "2025-02-16T03:27:18.629601Z",
     "shell.execute_reply": "2025-02-16T03:27:18.629000Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "prompt_value = prompt.invoke({\"dish\": \"カレー\"})\n",
    "ai_message = model.invoke(prompt_value)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:18.632331Z",
     "iopub.status.busy": "2025-02-16T03:27:18.632098Z",
     "iopub.status.idle": "2025-02-16T03:27:18.636846Z",
     "shell.execute_reply": "2025-02-16T03:27:18.636358Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(description=\"steps to make the dish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:18.638930Z",
     "iopub.status.busy": "2025-02-16T03:27:18.638715Z",
     "iopub.status.idle": "2025-02-16T03:27:18.641096Z",
     "shell.execute_reply": "2025-02-16T03:27:18.640833Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:18.642202Z",
     "iopub.status.busy": "2025-02-16T03:27:18.642117Z",
     "iopub.status.idle": "2025-02-16T03:27:18.644287Z",
     "shell.execute_reply": "2025-02-16T03:27:18.644094Z"
    }
   },
   "outputs": [],
   "source": [
    "recipe = output_parser.invoke(ai_message)\n",
    "print(type(recipe))\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:18.645291Z",
     "iopub.status.busy": "2025-02-16T03:27:18.645218Z",
     "iopub.status.idle": "2025-02-16T03:27:18.647097Z",
     "shell.execute_reply": "2025-02-16T03:27:18.646894Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "ai_message = AIMessage(content=\"こんにちは。私はAIアシスタントです。\")\n",
    "output = output_parser.invoke(ai_message)\n",
    "print(type(output))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Expression Language（LCEL）の概要\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt と model の連鎖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:18.648115Z",
     "iopub.status.busy": "2025-02-16T03:27:18.648025Z",
     "iopub.status.idle": "2025-02-16T03:27:18.657081Z",
     "shell.execute_reply": "2025-02-16T03:27:18.656863Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:18.658191Z",
     "iopub.status.busy": "2025-02-16T03:27:18.658109Z",
     "iopub.status.idle": "2025-02-16T03:27:18.659650Z",
     "shell.execute_reply": "2025-02-16T03:27:18.659442Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:18.660617Z",
     "iopub.status.busy": "2025-02-16T03:27:18.660542Z",
     "iopub.status.idle": "2025-02-16T03:27:28.476286Z",
     "shell.execute_reply": "2025-02-16T03:27:28.475674Z"
    }
   },
   "outputs": [],
   "source": [
    "ai_message = chain.invoke({\"dish\": \"カレー\"})\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StrOutputParser を連鎖に追加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:28.485579Z",
     "iopub.status.busy": "2025-02-16T03:27:28.485333Z",
     "iopub.status.idle": "2025-02-16T03:27:36.827449Z",
     "shell.execute_reply": "2025-02-16T03:27:36.826907Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "output = chain.invoke({\"dish\": \"カレー\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PydanticOutputParser を使う連鎖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:36.830150Z",
     "iopub.status.busy": "2025-02-16T03:27:36.829897Z",
     "iopub.status.idle": "2025-02-16T03:27:36.850521Z",
     "shell.execute_reply": "2025-02-16T03:27:36.850114Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "_system_prompt = \"\"\"\\\n",
    "ユーザーが入力した料理のレシピを考えてください。\n",
    "\n",
    "出力は以下のJSON形式にしてください。\n",
    "{{\n",
    "  \"ingredients\": [\"材料1\", \"材料2\"]\n",
    "  \"steps\": [\"ステップ1\", \"ステップ2\"]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", _system_prompt),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).bind(\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:36.852557Z",
     "iopub.status.busy": "2025-02-16T03:27:36.852341Z",
     "iopub.status.idle": "2025-02-16T03:27:36.855995Z",
     "shell.execute_reply": "2025-02-16T03:27:36.855612Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
    "\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:36.857486Z",
     "iopub.status.busy": "2025-02-16T03:27:36.857357Z",
     "iopub.status.idle": "2025-02-16T03:27:36.859306Z",
     "shell.execute_reply": "2025-02-16T03:27:36.858989Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:36.860766Z",
     "iopub.status.busy": "2025-02-16T03:27:36.860656Z",
     "iopub.status.idle": "2025-02-16T03:27:40.383034Z",
     "shell.execute_reply": "2025-02-16T03:27:40.382650Z"
    }
   },
   "outputs": [],
   "source": [
    "recipe = chain.invoke({\"dish\": \"カレー\"})\n",
    "print(type(recipe))\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （補足）with_structured_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:40.384612Z",
     "iopub.status.busy": "2025-02-16T03:27:40.384491Z",
     "iopub.status.idle": "2025-02-16T03:27:44.035231Z",
     "shell.execute_reply": "2025-02-16T03:27:44.034680Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain = prompt | model.with_structured_output(Recipe)\n",
    "\n",
    "recipe = chain.invoke({\"dish\": \"カレー\"})\n",
    "print(type(recipe))\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG (検索拡張生成) の基礎\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain での RAG の実装をステップバイステップで動かそう\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:44.036679Z",
     "iopub.status.busy": "2025-02-16T03:27:44.036570Z",
     "iopub.status.idle": "2025-02-16T03:27:44.201957Z",
     "shell.execute_reply": "2025-02-16T03:27:44.201712Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path=\"../tmp/langchain\",\n",
    "    glob=\"**/*.mdx\",\n",
    "    loader_cls=TextLoader,\n",
    ")\n",
    "\n",
    "raw_docs = loader.load()\n",
    "print(len(raw_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:44.203095Z",
     "iopub.status.busy": "2025-02-16T03:27:44.203000Z",
     "iopub.status.idle": "2025-02-16T03:27:44.239192Z",
     "shell.execute_reply": "2025-02-16T03:27:44.238913Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "docs = text_splitter.split_documents(raw_docs)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:44.242853Z",
     "iopub.status.busy": "2025-02-16T03:27:44.242735Z",
     "iopub.status.idle": "2025-02-16T03:27:44.252278Z",
     "shell.execute_reply": "2025-02-16T03:27:44.252064Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:44.253298Z",
     "iopub.status.busy": "2025-02-16T03:27:44.253212Z",
     "iopub.status.idle": "2025-02-16T03:27:44.555402Z",
     "shell.execute_reply": "2025-02-16T03:27:44.554642Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"AWSのS3からデータを読み込むためのDocument loaderはありますか？\"\n",
    "\n",
    "vector = embeddings.embed_query(query)\n",
    "print(len(vector))\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:44.558762Z",
     "iopub.status.busy": "2025-02-16T03:27:44.558405Z",
     "iopub.status.idle": "2025-02-16T03:27:55.745826Z",
     "shell.execute_reply": "2025-02-16T03:27:55.745522Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "db = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:55.748475Z",
     "iopub.status.busy": "2025-02-16T03:27:55.748369Z",
     "iopub.status.idle": "2025-02-16T03:27:55.750064Z",
     "shell.execute_reply": "2025-02-16T03:27:55.749884Z"
    }
   },
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:55.751074Z",
     "iopub.status.busy": "2025-02-16T03:27:55.751001Z",
     "iopub.status.idle": "2025-02-16T03:27:56.587651Z",
     "shell.execute_reply": "2025-02-16T03:27:56.587145Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"AWSのS3からデータを読み込むためのDocument loaderはありますか？\"\n",
    "\n",
    "context_docs = retriever.invoke(query)\n",
    "print(f\"len = {len(context_docs)}\")\n",
    "\n",
    "first_doc = context_docs[0]\n",
    "print(f\"metadata = {first_doc.metadata}\")\n",
    "print(first_doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL を使った RAG の Chain の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:56.590948Z",
     "iopub.status.busy": "2025-02-16T03:27:56.590638Z",
     "iopub.status.idle": "2025-02-16T03:27:56.612217Z",
     "shell.execute_reply": "2025-02-16T03:27:56.611783Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "\n",
    "文脈: \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "質問: {question}\n",
    "''')\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T03:27:56.614857Z",
     "iopub.status.busy": "2025-02-16T03:27:56.614637Z",
     "iopub.status.idle": "2025-02-16T03:27:58.293394Z",
     "shell.execute_reply": "2025-02-16T03:27:58.292834Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "output = chain.invoke(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
